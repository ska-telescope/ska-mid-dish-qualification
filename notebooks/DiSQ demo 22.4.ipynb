{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DiSQ is intended to be used in two ways:\n",
    "- Using the engineering GUI to monitor the dish structure and run simple commands.\n",
    "- Using the sculib and data logger in Python scripts for more complex testing.\n",
    "\n",
    "Both methods require an OPCUA server to connect to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disq import sculib, logger, hdf5_to_graph, hdf5_to_csv\n",
    "from time import sleep\n",
    "# Necessary for interactive graph window:\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up client\n",
    "client = sculib.SCU(host=\"127.0.0.1\", port=4840, endpoint=\"/OPCUA/SimpleServer\", namespace=\"CETC54\", username=\"LMC\", password=\"lmc\")\n",
    "# Set up logger\n",
    "data_logger = logger.Logger(high_level_library=client)\n",
    "# Tell the logger what nodes to subscribe to\n",
    "nodes = [\"Azimuth.p_Act\", \"Elevation.p_Act\"]\n",
    "period = 100 # In milliseconds\n",
    "data_logger.add_nodes(nodes, period)\n",
    "# Start the data logging\n",
    "data_logger.start()\n",
    "# Run the test\n",
    "#client.commands[\"CommandArbiter.TakeReleaseAuth\"](False, \"Tester\")\n",
    "#client.commands[\"CommandArbiter.TakeReleaseAuth\"](True, \"Tester\")\n",
    "AzElVel = [90.0, 15.0, 3.0, 1.0]\n",
    "#AzElVel = [10.0, 45.0, 3.0, 1.0]\n",
    "msg = client.commands[\"Management.Slew2AbsAzEl\"](*AzElVel)\n",
    "print(f\"msg = {msg}\")\n",
    "#client.commands[\"Management.Stow\"]\n",
    "sleep(25)\n",
    "data_logger.stop()\n",
    "data_logger.wait_for_completion()\n",
    "# Finished writing HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grapher object and get the file name from the data logger\n",
    "grapher = hdf5_to_graph.Grapher()\n",
    "file = data_logger.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what nodes are in the file, and the file start and stop times\n",
    "grapher.hdf5_info(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the graph from the desired nodes\n",
    "grapher.graph(file, *nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = hdf5_to_csv.Converter()\n",
    "output_file = \"results/\" + data_logger.start_time.isoformat() + \".csv\"\n",
    "step = 100 # In milliseconds\n",
    "converter.make_csv(file, output_file, nodes, step_ms=step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
